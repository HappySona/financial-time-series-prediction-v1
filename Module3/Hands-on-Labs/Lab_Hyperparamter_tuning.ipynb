{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_Hyperparamter_tuning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "G1CLeL2q68gI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ]
    },
    {
      "metadata": {
        "id": "TW1mvJM17IE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf  # deep learning library. Tensors are just multi-dimensional arrays\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYovY1PK7WAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ]
    },
    {
      "metadata": {
        "id": "YiaKyTYP7KUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c7c3a0c7-81d8-427c-a964-4fcc5fb8a5f4"
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xzwvjuka7Ydx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = tf.keras.utils.normalize(x_train, axis=1)  # scales data between 0 and 1\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)  # scales data between 0 and 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNxXKoTh7aRi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compare Learning Rates"
      ]
    },
    {
      "metadata": {
        "id": "zpgWCeHE7cT4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "dflist = []\n",
        "\n",
        "learning_rates = [0.01, 0.05, 0.1, 0.5]\n",
        "\n",
        "for lr in learning_rates:\n",
        "\n",
        "  K.clear_session()\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "  model.compile(optimizer=SGD(lr=lr),  # Good default optimizer to start with\n",
        "                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "                metrics=['accuracy'])  # what to track\n",
        "\n",
        "  h =  model.fit(x_train, y_train, batch_size=16, verbose=0)  \n",
        "\n",
        "  dflist.append(pd.DataFrame(h.history, index=h.epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0H51l_jm8uEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea930cb5-399d-4c2a-d359-aa4653d73e22"
      },
      "cell_type": "code",
      "source": [
        "h.history.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "gf9ZdhFx7sJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s93RIFcG7gdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([learning_rates, metrics_reported],\n",
        "                                 names=['learning_rate', 'metric'])\n",
        "\n",
        "historydf.columns = idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8LH8r7s8126",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "686fc1b2-b74a-4b77-d6ea-628325c2a1fb"
      },
      "cell_type": "code",
      "source": [
        "historydf"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>learning_rate</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.01</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.05</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.10</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.81235</td>\n",
              "      <td>0.741103</td>\n",
              "      <td>0.8938</td>\n",
              "      <td>0.367638</td>\n",
              "      <td>0.912683</td>\n",
              "      <td>0.292995</td>\n",
              "      <td>0.92175</td>\n",
              "      <td>0.259577</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "learning_rate     0.01              0.05                0.10            \\\n",
              "metric             acc      loss     acc      loss       acc      loss   \n",
              "0              0.81235  0.741103  0.8938  0.367638  0.912683  0.292995   \n",
              "\n",
              "learning_rate     0.50            \n",
              "metric             acc      loss  \n",
              "0              0.92175  0.259577  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "zdHAw21y7jFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Batch Size"
      ]
    },
    {
      "metadata": {
        "id": "F3Oqw_uu7luh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "batch_sizes = [16, 32, 64, 128]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "  K.clear_session()\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "  model.compile(optimizer='sgd',  # Good default optimizer to start with\n",
        "                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "                metrics=['accuracy'])  # what to track\n",
        "\n",
        "  h =  model.fit(x_train, y_train, batch_size=batch_size, verbose=0)  \n",
        "\n",
        "  dflist.append(pd.DataFrame(h.history, index=h.epoch))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYng3HBE9aik",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist, axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([batch_sizes, metrics_reported],\n",
        "                                 names=['batch_size', 'metric'])\n",
        "historydf.columns = idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhWMLcct9bid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "8a60b51d-93b1-4484-cf31-9cc014149f75"
      },
      "cell_type": "code",
      "source": [
        "historydf"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>batch_size</th>\n",
              "      <th colspan=\"2\" halign=\"left\">16</th>\n",
              "      <th colspan=\"2\" halign=\"left\">32</th>\n",
              "      <th colspan=\"2\" halign=\"left\">64</th>\n",
              "      <th colspan=\"2\" halign=\"left\">128</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.805883</td>\n",
              "      <td>0.758128</td>\n",
              "      <td>0.739983</td>\n",
              "      <td>1.078245</td>\n",
              "      <td>0.613867</td>\n",
              "      <td>1.606198</td>\n",
              "      <td>0.46</td>\n",
              "      <td>2.013939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "batch_size       16                  32                  64              128  \\\n",
              "metric           acc      loss       acc      loss       acc      loss   acc   \n",
              "0           0.805883  0.758128  0.739983  1.078245  0.613867  1.606198  0.46   \n",
              "\n",
              "batch_size            \n",
              "metric          loss  \n",
              "0           2.013939  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "PvtJZcqo9cRt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizers"
      ]
    },
    {
      "metadata": {
        "id": "Re3tla6W9fQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1iHWN0jS9hVt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "optimizers = ['SGD(lr=0.01)',\n",
        "              'SGD(lr=0.01, momentum=0.3)',\n",
        "              'SGD(lr=0.01, momentum=0.3, nesterov=True)',  \n",
        "              'Adam(lr=0.01)',\n",
        "              'Adagrad(lr=0.01)',\n",
        "              'RMSprop(lr=0.01)']\n",
        "\n",
        "for opt_name in optimizers:\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "  model.compile(optimizer=eval(opt_name),  # Good default optimizer to start with\n",
        "                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "                metrics=['accuracy'])  # what to track\n",
        "\n",
        "  h =  model.fit(x_train, y_train, batch_size=16, verbose=0)  \n",
        "\n",
        "  dflist.append(pd.DataFrame(h.history, index=h.epoch))     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1EUs4g8E9o_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist, axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([optimizers, metrics_reported],\n",
        "                                 names=['optimizers', 'metric'])\n",
        "historydf.columns = idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVvXFudm9qca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "51943a83-a293-4c47-91e3-1c307a815a90"
      },
      "cell_type": "code",
      "source": [
        "historydf"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>optimizers</th>\n",
              "      <th colspan=\"2\" halign=\"left\">SGD(lr=0.01)</th>\n",
              "      <th colspan=\"2\" halign=\"left\">SGD(lr=0.01, momentum=0.3)</th>\n",
              "      <th colspan=\"2\" halign=\"left\">SGD(lr=0.01, momentum=0.3, nesterov=True)</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Adam(lr=0.01)</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Adagrad(lr=0.01)</th>\n",
              "      <th colspan=\"2\" halign=\"left\">RMSprop(lr=0.01)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.800367</td>\n",
              "      <td>0.787923</td>\n",
              "      <td>0.832383</td>\n",
              "      <td>0.630575</td>\n",
              "      <td>0.84125</td>\n",
              "      <td>0.619871</td>\n",
              "      <td>0.91785</td>\n",
              "      <td>0.290038</td>\n",
              "      <td>0.92875</td>\n",
              "      <td>0.240809</td>\n",
              "      <td>0.91375</td>\n",
              "      <td>0.414608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "optimizers SGD(lr=0.01)           SGD(lr=0.01, momentum=0.3)            \\\n",
              "metric              acc      loss                        acc      loss   \n",
              "0              0.800367  0.787923                   0.832383  0.630575   \n",
              "\n",
              "optimizers SGD(lr=0.01, momentum=0.3, nesterov=True)           Adam(lr=0.01)  \\\n",
              "metric                                           acc      loss           acc   \n",
              "0                                            0.84125  0.619871       0.91785   \n",
              "\n",
              "optimizers           Adagrad(lr=0.01)           RMSprop(lr=0.01)            \n",
              "metric          loss              acc      loss              acc      loss  \n",
              "0           0.290038          0.92875  0.240809          0.91375  0.414608  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "dD_mMo769r1D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ]
    },
    {
      "metadata": {
        "id": "SNSzjk-59wXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dflist = []\n",
        "\n",
        "initializers = ['zeros', 'uniform', 'normal',\n",
        "                'he_normal', 'lecun_uniform']\n",
        "\n",
        "for init in initializers:\n",
        "\n",
        "  K.clear_session()\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
        "  model.add(tf.keras.layers.Dense(128, kernel_initializer=init, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(128, kernel_initializer=init, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "  model.add(tf.keras.layers.Dense(10, kernel_initializer=init, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "  model.compile(optimizer='rmsprop',  # Good default optimizer to start with\n",
        "                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "                metrics=['accuracy'])  # what to track\n",
        "\n",
        "  h =  model.fit(x_train, y_train, batch_size=16, verbose=0)  \n",
        "\n",
        "  \n",
        "  dflist.append(pd.DataFrame(h.history, index=h.epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DzTZ-geS-BBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "historydf = pd.concat(dflist, axis=1)\n",
        "metrics_reported = dflist[0].columns\n",
        "idx = pd.MultiIndex.from_product([initializers, metrics_reported],\n",
        "                                 names=['initializers', 'metric'])\n",
        "\n",
        "historydf.columns = idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "404iTWdW-B55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "346816bd-3ee7-4759-c266-dff45aeb98df"
      },
      "cell_type": "code",
      "source": [
        "historydf"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>initializers</th>\n",
              "      <th colspan=\"2\" halign=\"left\">zeros</th>\n",
              "      <th colspan=\"2\" halign=\"left\">uniform</th>\n",
              "      <th colspan=\"2\" halign=\"left\">normal</th>\n",
              "      <th colspan=\"2\" halign=\"left\">he_normal</th>\n",
              "      <th colspan=\"2\" halign=\"left\">lecun_uniform</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.111767</td>\n",
              "      <td>2.301561</td>\n",
              "      <td>0.910033</td>\n",
              "      <td>0.302547</td>\n",
              "      <td>0.919583</td>\n",
              "      <td>0.274092</td>\n",
              "      <td>0.92925</td>\n",
              "      <td>0.24182</td>\n",
              "      <td>0.923467</td>\n",
              "      <td>0.252066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "initializers     zeros             uniform              normal            \\\n",
              "metric             acc      loss       acc      loss       acc      loss   \n",
              "0             0.111767  2.301561  0.910033  0.302547  0.919583  0.274092   \n",
              "\n",
              "initializers he_normal          lecun_uniform            \n",
              "metric             acc     loss           acc      loss  \n",
              "0              0.92925  0.24182      0.923467  0.252066  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}